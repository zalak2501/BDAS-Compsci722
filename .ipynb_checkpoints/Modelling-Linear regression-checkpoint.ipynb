{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Trying linear regression to see if this dataset can be better on regression than Clustering!\n",
    "\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.3.2-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Modelling').getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----------+----------+------+--------+---------+--------+\n",
      "|Country|TIME|  Sex|GDPsubject| GDP Value|Impexp|    Cost|pte_value|se_value|\n",
      "+-------+----+-----+----------+----------+------+--------+---------+--------+\n",
      "|    AUS|2013|WOMEN|       TOT|1102723.05|   IMP|246949.7|    38.14|    7.89|\n",
      "|    AUS|2013|  MEN|       TOT|1102723.05|   IMP|246949.7|    13.65|   11.97|\n",
      "|    AUS|2013|  TOT|       TOT|1102723.05|   IMP|246949.7|    24.88|    10.1|\n",
      "|    AUS|2013|WOMEN|       TOT|1102723.05|   EXP|254201.7|    38.14|    7.89|\n",
      "|    AUS|2013|  MEN|       TOT|1102723.05|   EXP|254201.7|    13.65|   11.97|\n",
      "|    AUS|2013|  TOT|       TOT|1102723.05|   EXP|254201.7|    24.88|    10.1|\n",
      "|    AUS|2014|WOMEN|       TOT|1116293.11|   IMP|238300.4|    38.33|    7.98|\n",
      "|    AUS|2014|  MEN|       TOT|1116293.11|   IMP|238300.4|    14.03|   12.05|\n",
      "|    AUS|2014|  TOT|       TOT|1116293.11|   IMP|238300.4|    25.21|   10.18|\n",
      "|    AUS|2014|WOMEN|       TOT|1116293.11|   EXP|240425.8|    38.33|    7.98|\n",
      "|    AUS|2014|  MEN|       TOT|1116293.11|   EXP|240425.8|    14.03|   12.05|\n",
      "|    AUS|2014|  TOT|       TOT|1116293.11|   EXP|240425.8|    25.21|   10.18|\n",
      "|    AUS|2015|WOMEN|       TOT|1128361.01|   IMP|207262.8|    37.97|    8.15|\n",
      "|    AUS|2015|  MEN|       TOT|1128361.01|   IMP|207262.8|    14.29|   12.11|\n",
      "|    AUS|2015|  TOT|       TOT|1128361.01|   IMP|207262.8|    25.24|   10.28|\n",
      "|    AUS|2015|WOMEN|       TOT|1128361.01|   EXP|188096.6|    37.97|    8.15|\n",
      "|    AUS|2015|  MEN|       TOT|1128361.01|   EXP|188096.6|    14.29|   12.11|\n",
      "|    AUS|2015|  TOT|       TOT|1128361.01|   EXP|188096.6|    25.24|   10.28|\n",
      "|    AUS|2016|WOMEN|       TOT|1181218.13|   IMP|198519.0|    38.35|    8.13|\n",
      "|    AUS|2016|  MEN|       TOT|1181218.13|   IMP|198519.0|    15.06|   11.71|\n",
      "+-------+----+-----+----------+----------+------+--------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------+-----+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+-------+--------+--------+-----------------------------+------------------------+---------------------+------------------------------------+--------------------------------------------+------------------------------------------+----------------------------------------+--------------------------------------+\n",
      "|       Country|  Sex|2011_fte|2012_fte|2013_fte|2014_fte|2015_fte|2016_fte| 2011gwg| 2012gwg| 2013gwg| 2014gwg| 2015gwg| 2016gwg|2000_gnif|2005_gnif|2010_gnif|2011_gnif|2012_gnif|2013_gnif|2014_gnif|2015_gnif|2000_gni|2005_gni|2010_gni|2011_gni|2012_gni|2013_gni|2014gni|2015_gni|GII Rank|Gender Inequality Index (GII)|Maternal Mortality Ratio|Adolescent Birth Rate|Percent Representation in Parliament|Population with Secondary Education (Female)|Population with Secondary Education (Male)|Labour Force Participation Rate (Female)|Labour Force Participation Rate (Male)|\n",
      "+--------------+-----+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+-------+--------+--------+-----------------------------+------------------------+---------------------+------------------------------------+--------------------------------------------+------------------------------------------+----------------------------------------+--------------------------------------+\n",
      "|     Australia|  Men|    80.2|    79.8|    78.7|    77.7|    77.9|    77.2|    16.0|    13.8|    18.0|    15.4|    13.0|    14.3|    26268|    29848|    31749|    32039|    32968|    33478|    33751|    34271|   45151|   49034|   47883|   48125|   49539|   50135|  50577|   51386|       2|                         0.11|                       6|                 12.1|                                30.5|                                        94.3|                                      94.6|                                    58.8|                                  71.8|\n",
      "|     Australia|Women|    51.8|    51.8|    51.7|    51.1|    52.1|    52.3|    16.0|    13.8|    18.0|    15.4|    13.0|    14.3|    26268|    29848|    31749|    32039|    32968|    33478|    33751|    34271|   45151|   49034|   47883|   48125|   49539|   50135|  50577|   51386|       2|                         0.11|                       6|                 12.1|                                30.5|                                        94.3|                                      94.6|                                    58.8|                                  71.8|\n",
      "|       Austria|  Men|    80.0|    79.6|    78.4|    76.9|    76.5|    76.7|    18.6|    18.2|    18.1|    17.7|    17.0|14.08125|    23830|    25997|    29036|    29703|    29943|    30097|    29753|    29835|   53118|   56435|   58364|   59355|   59112|   58828|  57874|   57882|      23|                        0.053|                       4|                  4.1|                                30.3|                                       100.0|                                     100.0|                                    54.6|                                  67.7|\n",
      "|       Austria|Women|    54.0|    54.3|    54.1|    53.5|    53.5|    54.0|    18.6|    18.2|    18.1|    17.7|    17.0|14.08125|    23830|    25997|    29036|    29703|    29943|    30097|    29753|    29835|   53118|   56435|   58364|   59355|   59112|   58828|  57874|   57882|      23|                        0.053|                       4|                  4.1|                                30.3|                                       100.0|                                     100.0|                                    54.6|                                  67.7|\n",
      "|       Belgium|  Men|    67.9|    67.8|    67.9|    66.9|    66.4|    67.2|     5.8|     6.4|     5.9|     3.3|     4.7|14.08125|    26700|    29608|    32273|    31633|    31989|    32088|    32345|    32422|   49334|   50113|   51932|   51175|   51484|   50255|  50356|   50352|      21|                        0.063|                       6|                  6.7|                                42.4|                                        77.5|                                      82.9|                                    47.5|                                  59.3|\n",
      "|       Belgium|Women|    46.3|    46.5|    47.2|    48.0|    48.2|    48.2|     5.8|     6.4|     5.9|     3.3|     4.7|14.08125|    26700|    29608|    32273|    31633|    31989|    32088|    32345|    32422|   49334|   50113|   51932|   51175|   51484|   50255|  50356|   50352|      21|                        0.063|                       6|                  6.7|                                42.4|                                        77.5|                                      82.9|                                    47.5|                                  59.3|\n",
      "|         Chile|  Men|    83.2|    83.1|    82.9|    81.2|    81.0|    79.5|    16.0|14.08125|    10.7|14.08125|    21.1|14.08125|     7569|     8943|    12247|    13030|    13899|    14446|    14737|    14955|   20954|   22453|   23995|   25422|   26889|   27711|  28147|   28556|      42|                        0.338|                      22|                 55.3|                                15.8|                                        73.3|                                      76.4|                                    49.2|                                  74.8|\n",
      "|         Chile|Women|    47.6|    48.9|    49.6|    49.9|    49.8|    49.6|    16.0|14.08125|    10.7|14.08125|    21.1|14.08125|     7569|     8943|    12247|    13030|    13899|    14446|    14737|    14955|   20954|   22453|   23995|   25422|   26889|   27711|  28147|   28556|      42|                        0.338|                      22|                 55.3|                                15.8|                                        73.3|                                      76.4|                                    49.2|                                  74.8|\n",
      "|Czech Republic|  Men|    78.9|    79.1|    79.5|    80.6|    81.4|    82.7|    16.3|    15.3|    15.4|    16.3|    16.5|    16.3|    15028|    17677|    18587|    19408|    19631|    19624|    20053|    21001|   26497|   31435|   33642|   33720|   33685|   33488|  33941|   35540|      28|                        0.091|                       5|                  4.9|                                18.9|                                        99.9|                                      99.7|                                    51.1|                                  68.3|\n",
      "|Czech Republic|Women|    55.8|    56.5|    57.3|    58.3|    60.1|    61.8|    16.3|    15.3|    15.4|    16.3|    16.5|    16.3|    15028|    17677|    18587|    19408|    19631|    19624|    20053|    21001|   26497|   31435|   33642|   33720|   33685|   33488|  33941|   35540|      28|                        0.091|                       5|                  4.9|                                18.9|                                        99.9|                                      99.7|                                    51.1|                                  68.3|\n",
      "|       Denmark|  Men|    68.1|    67.1|    66.9|    67.4|    68.2|    67.7|     7.9|     7.0|     6.8|     6.3|     5.8|14.08125|    31989|    34844|    36081|    36518|    36504|    36724|    36749|    36857|   49941|   53861|   51472|   52071|   51825|   52123|  52149|   52293|       4|                        0.048|                       5|                  5.1|                                38.0|                                        95.5|                                      96.6|                                    58.7|                                  66.4|\n",
      "|       Denmark|Women|    54.9|    54.7|    54.8|    54.3|    54.6|    55.1|     7.9|     7.0|     6.8|     6.3|     5.8|14.08125|    31989|    34844|    36081|    36518|    36504|    36724|    36749|    36857|   49941|   53861|   51472|   52071|   51825|   52123|  52149|   52293|       4|                        0.048|                       5|                  5.1|                                38.0|                                        95.5|                                      96.6|                                    58.7|                                  66.4|\n",
      "|       Estonia|  Men|    68.1|    70.2|    71.5|    72.7|    75.3|    74.8|14.08125|14.08125|14.08125|    28.3|14.08125|14.08125|    11513|    17075|    17665|    19073|    20339|    21105|    21590|    21976|   18499|   26329|   24932|   26983|   28838|   29986|  30859|   31347|      30|                        0.164|                      11|                 16.8|                                19.8|                                       100.0|                                     100.0|                                    56.2|                                  68.9|\n",
      "|       Estonia|Women|    58.5|    60.5|    61.7|    62.7|    63.6|    63.5|14.08125|14.08125|14.08125|    28.3|14.08125|14.08125|    11513|    17075|    17665|    19073|    20339|    21105|    21590|    21976|   18499|   26329|   24932|   26983|   28838|   29986|  30859|   31347|      30|                        0.164|                      11|                 16.8|                                19.8|                                       100.0|                                     100.0|                                    56.2|                                  68.9|\n",
      "|       Finland|  Men|    69.5|    69.4|    67.4|    67.7|    67.4|    68.4|    18.6|    18.7|    20.2|    19.6|    18.1|14.08125|    27013|    32587|    33507|    33122|    33673|    32105|    32029|    32081|   41926|   45421|   46658|   48013|   45928|   46428|  45851|   45870|      24|                        0.075|                       4|                  9.2|                                42.5|                                       100.0|                                     100.0|                                    55.7|                                  64.0|\n",
      "|       Finland|Women|    59.3|    59.6|    58.9|    59.1|    59.1|    58.5|    18.6|    18.7|    20.2|    19.6|    18.1|14.08125|    27013|    32587|    33507|    33122|    33673|    32105|    32029|    32081|   41926|   45421|   46658|   48013|   45928|   46428|  45851|   45870|      24|                        0.075|                       4|                  9.2|                                42.5|                                       100.0|                                     100.0|                                    55.7|                                  64.0|\n",
      "|        France|  Men|    69.9|    69.6|    68.6|    67.8|    67.5|    68.0|14.08125|14.08125|14.08125|     9.9|14.08125|14.08125|    26374|    28405|    30860|    31415|    31440|    31532|    31519|    31734|   44891|   46091|   44486|   45314|   44384|   44484|  44480|   44783|      22|                        0.088|                      12|                  5.7|                                25.7|                                        78.0|                                      83.2|                                    50.7|                                  61.6|\n",
      "|        France|Women|    51.8|    51.9|    51.8|    52.1|    52.4|    52.8|14.08125|14.08125|14.08125|     9.9|14.08125|14.08125|    26374|    28405|    30860|    31415|    31440|    31532|    31519|    31734|   44891|   46091|   44486|   45314|   44384|   44484|  44480|   44783|      22|                        0.088|                      12|                  5.7|                                25.7|                                        78.0|                                      83.2|                                    50.7|                                  61.6|\n",
      "|       Germany|  Men|    77.5|    77.7|    77.2|    77.0|    76.6|    77.0|    16.9|    15.6|    14.1|    17.4|    15.8|    15.5|    26453|    29535|    32718|    33944|    34580|    34306|    35357|    35868|   47501|   47378|   50594|   52839|   53904|   52401|  53937|   54450|       6|                        0.041|                       7|                  3.8|                                36.9|                                        96.3|                                      97.0|                                    53.6|                                  66.4|\n",
      "|       Germany|Women|    51.5|    51.8|    52.3|    53.0|    53.2|    54.1|    16.9|    15.6|    14.1|    17.4|    15.8|    15.5|    26453|    29535|    32718|    33944|    34580|    34306|    35357|    35868|   47501|   47378|   50594|   52839|   53904|   52401|  53937|   54450|       6|                        0.041|                       7|                  3.8|                                36.9|                                        96.3|                                      97.0|                                    53.6|                                  66.4|\n",
      "+--------------+-----+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+-------+--------+--------+-----------------------------+------------------------+---------------------+------------------------------------+--------------------------------------------+------------------------------------------+----------------------------------------+--------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using the 2 obtained merged datasets from previous steps\n",
    "\n",
    "final1  = spark.read.csv(\"Updated Datasets after cleaning/final1.csv\",header=True,inferSchema=True) \n",
    "final2  = spark.read.csv(\"Updated Datasets after cleaning/final2.csv\",header=True,inferSchema=True) \n",
    "\n",
    "final1.show()\n",
    "final2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- TIME: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- GDPsubject: string (nullable = true)\n",
      " |-- GDP Value: double (nullable = true)\n",
      " |-- Impexp: string (nullable = true)\n",
      " |-- Cost: double (nullable = true)\n",
      " |-- pte_value: double (nullable = true)\n",
      " |-- se_value: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Country='AUS', TIME=2013, Sex='WOMEN', GDPsubject='TOT', GDP Value=1102723.05, Impexp='IMP', Cost=246949.7, pte_value=38.14, se_value=7.89, features=DenseVector([246949.7, 38.14, 7.89]))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# The input columns are the feature column names, and the output column is what you'd like the new column to be named. \n",
    "vector_assembler = VectorAssembler(inputCols = ['Cost','pte_value','se_value'], outputCol = 'features')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Now that we've created the assembler variable, let's actually transform the data.\n",
    "vector_output = vector_assembler.transform(final1)\n",
    "\n",
    "\n",
    "# Using print schema, you see that the features output column has been added. \n",
    "vector_output.printSchema()\n",
    "\n",
    "\n",
    "# You can see that the features column is a DenseVector that combines the various features as expected.\n",
    "vector_output.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- 2011_fte: double (nullable = true)\n",
      " |-- 2012_fte: double (nullable = true)\n",
      " |-- 2013_fte: double (nullable = true)\n",
      " |-- 2014_fte: double (nullable = true)\n",
      " |-- 2015_fte: double (nullable = true)\n",
      " |-- 2016_fte: double (nullable = true)\n",
      " |-- 2011gwg: double (nullable = true)\n",
      " |-- 2012gwg: double (nullable = true)\n",
      " |-- 2013gwg: double (nullable = true)\n",
      " |-- 2014gwg: double (nullable = true)\n",
      " |-- 2015gwg: double (nullable = true)\n",
      " |-- 2016gwg: double (nullable = true)\n",
      " |-- 2000_gnif: integer (nullable = true)\n",
      " |-- 2005_gnif: integer (nullable = true)\n",
      " |-- 2010_gnif: integer (nullable = true)\n",
      " |-- 2011_gnif: integer (nullable = true)\n",
      " |-- 2012_gnif: integer (nullable = true)\n",
      " |-- 2013_gnif: integer (nullable = true)\n",
      " |-- 2014_gnif: integer (nullable = true)\n",
      " |-- 2015_gnif: integer (nullable = true)\n",
      " |-- 2000_gni: integer (nullable = true)\n",
      " |-- 2005_gni: integer (nullable = true)\n",
      " |-- 2010_gni: integer (nullable = true)\n",
      " |-- 2011_gni: integer (nullable = true)\n",
      " |-- 2012_gni: integer (nullable = true)\n",
      " |-- 2013_gni: integer (nullable = true)\n",
      " |-- 2014gni: integer (nullable = true)\n",
      " |-- 2015_gni: integer (nullable = true)\n",
      " |-- GII Rank: integer (nullable = true)\n",
      " |-- Gender Inequality Index (GII): double (nullable = true)\n",
      " |-- Maternal Mortality Ratio: integer (nullable = true)\n",
      " |-- Adolescent Birth Rate: double (nullable = true)\n",
      " |-- Percent Representation in Parliament: double (nullable = true)\n",
      " |-- Population with Secondary Education (Female): double (nullable = true)\n",
      " |-- Population with Secondary Education (Male): double (nullable = true)\n",
      " |-- Labour Force Participation Rate (Female): double (nullable = true)\n",
      " |-- Labour Force Participation Rate (Male): double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Country='Australia', Sex='Men', 2011_fte=80.2, 2012_fte=79.8, 2013_fte=78.7, 2014_fte=77.7, 2015_fte=77.9, 2016_fte=77.2, 2011gwg=16.0, 2012gwg=13.8, 2013gwg=18.0, 2014gwg=15.4, 2015gwg=13.0, 2016gwg=14.3, 2000_gnif=26268, 2005_gnif=29848, 2010_gnif=31749, 2011_gnif=32039, 2012_gnif=32968, 2013_gnif=33478, 2014_gnif=33751, 2015_gnif=34271, 2000_gni=45151, 2005_gni=49034, 2010_gni=47883, 2011_gni=48125, 2012_gni=49539, 2013_gni=50135, 2014gni=50577, 2015_gni=51386, GII Rank=2, Gender Inequality Index (GII)=0.11, Maternal Mortality Ratio=6, Adolescent Birth Rate=12.1, Percent Representation in Parliament=30.5, Population with Secondary Education (Female)=94.3, Population with Secondary Education (Male)=94.6, Labour Force Participation Rate (Female)=58.8, Labour Force Participation Rate (Male)=71.8, features=DenseVector([30.5, 51386.0, 34271.0]))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#for seeing if these input can predict the 2016 gender wage gape or not?\n",
    "\n",
    "vector_assembler2 = VectorAssembler(inputCols = ['Percent Representation in Parliament','2015_gni','2015_gnif'], \n",
    "                                    outputCol = 'features')\n",
    "\n",
    "vector_output2 = vector_assembler2.transform(final2)\n",
    "vector_output2.printSchema()\n",
    "vector_output2.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(features=DenseVector([246949.7, 38.14, 7.89]), GDP Value=1102723.05)]\n",
      "+--------------------+----------+\n",
      "|            features| GDP Value|\n",
      "+--------------------+----------+\n",
      "|[246949.7,38.14,7...|1102723.05|\n",
      "|[246949.7,13.65,1...|1102723.05|\n",
      "|[246949.7,24.88,1...|1102723.05|\n",
      "+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Because the features have been combined into one vector, we no longer need them. Below we select the features and label.\n",
    "vector_output = vector_output.select(['features', 'GDP Value'])\n",
    "\n",
    "# You can see that the dataframe now only contains two columns. \n",
    "print(vector_output.head(1))\n",
    "vector_output.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(features=DenseVector([30.5, 51386.0, 34271.0]), 2016gwg=14.3)]\n",
      "+--------------------+--------+\n",
      "|            features| 2016gwg|\n",
      "+--------------------+--------+\n",
      "|[30.5,51386.0,342...|    14.3|\n",
      "|[30.5,51386.0,342...|    14.3|\n",
      "|[30.3,57882.0,298...|14.08125|\n",
      "+--------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_output2 = vector_output2.select(['features', '2016gwg'])\n",
    "print(vector_output2.head(1))\n",
    "vector_output2.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|        GDP Value|\n",
      "+-------+-----------------+\n",
      "|  count|             1332|\n",
      "|   mean|947248.7424474488|\n",
      "| stddev|2620082.536606752|\n",
      "|    min|         12784.97|\n",
      "|    max|           2.11E7|\n",
      "+-------+-----------------+\n",
      "\n",
      "+-------+-----------------+\n",
      "|summary|        GDP Value|\n",
      "+-------+-----------------+\n",
      "|  count|              576|\n",
      "|   mean|881000.3485416662|\n",
      "| stddev|2574203.125893797|\n",
      "|    min|         13431.52|\n",
      "|    max|           2.11E7|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's do a randomised 70/30 split. \n",
    "train_data,test_data = vector_output.randomSplit([0.7,0.3])\n",
    "\n",
    "# Let's see our training data.\n",
    "train_data.describe().show()\n",
    "\n",
    "# And our testing data.\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           2016gwg|\n",
      "+-------+------------------+\n",
      "|  count|                39|\n",
      "|   mean|14.066506410256412|\n",
      "| stddev|2.3682424150561503|\n",
      "|    min|               4.5|\n",
      "|    max|              18.1|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|           2016gwg|\n",
      "+-------+------------------+\n",
      "|  count|                25|\n",
      "|   mean|13.519250000000005|\n",
      "| stddev| 2.567052561629128|\n",
      "|    min|               4.5|\n",
      "|    max|              16.5|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's do a randomised 60/40 split. \n",
    "train_data2,test_data2 = vector_output2.randomSplit([0.6,0.4])\n",
    "\n",
    "# Let's see our training data.\n",
    "train_data2.describe().show()\n",
    "\n",
    "# And our testing data.\n",
    "test_data2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [3.323133611060712,-10793.001093395604,6590.061016754907]\n",
      "Intercept: -136246.32694589027\n",
      "\n",
      "RMSE: 1935001.2685033777\n",
      "R2: 0.3065675545265537\n",
      "\n",
      "Coefficients: [-0.00031901984408835073,-1.1461075031489649e-05,7.370379414726121e-05]\n",
      "Intercept: 12.348509562983768\n",
      "\n",
      "RMSE: 2.0633226886018208\n",
      "R2: 0.07364859375632093\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importing the LR package.\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Instantiate the instance.\n",
    "lr = LinearRegression(featuresCol='features', labelCol='GDP Value')\n",
    "lr2=LinearRegression(featuresCol='features', labelCol='2016gwg')\n",
    "# Fit the training data.\n",
    "\n",
    "train_data,test_data = vector_output.randomSplit([0.7,0.3])\n",
    "train_data2,test_data2 = vector_output2.randomSplit([0.6,0.4])\n",
    "\n",
    "lr_model = lr.fit(train_data)\n",
    "lr_model2 = lr2.fit(train_data2)\n",
    "# Print the coefficients.\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "\n",
    "# Print the intercept.\n",
    "print(\"Intercept: \" + str(lr_model.intercept) + \"\\n\")\n",
    "\n",
    "# Summarise the model and print out some evaluation metrics.\n",
    "training_summary = lr_model.summary\n",
    "\n",
    "# Print RMSE. \n",
    "print(\"RMSE: \" + str(training_summary.rootMeanSquaredError))\n",
    "\n",
    "# Print R2.\n",
    "print(\"R2: \" + str(training_summary.r2))\n",
    "\n",
    "#dataset 2\n",
    "\n",
    "# Print the coefficients.\n",
    "print(\"\\nCoefficients: \" + str(lr_model2.coefficients))\n",
    "\n",
    "# Print the intercept.\n",
    "print(\"Intercept: \" + str(lr_model2.intercept) + \"\\n\")\n",
    "\n",
    "\n",
    "# Summarise the model and print out some evaluation metrics.\n",
    "training_summary2 = lr_model2.summary\n",
    "\n",
    "# Print RMSE. \n",
    "print(\"RMSE: \" + str(training_summary2.rootMeanSquaredError))\n",
    "\n",
    "# Print R2.\n",
    "print(\"R2: \" + str(training_summary2.r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data: 2447853.913063798\n",
      "R2 on test data: 0.41581400773039257\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the modelagainst the test data.\n",
    "test_results = lr_model.evaluate(test_data)\n",
    "\n",
    "# And print the RMSE/R2. As expected, our RMSE and R2 are slightly worse when applying the testing set.\n",
    "print(\"RMSE on test data: \" + str(test_results.rootMeanSquaredError))\n",
    "print(\"R2 on test data: \" + str(test_results.r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data2: 2.907680264449592\n",
      "R2 on test data2: -0.00268188875019848\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model against the test data.\n",
    "test_results2 = lr_model2.evaluate(test_data2)\n",
    "\n",
    "# And print the RMSE/R2. As expected, our RMSE and R2 are slightly worse when applying the testing set.\n",
    "print(\"RMSE on test data2: \" + str(test_results2.rootMeanSquaredError))\n",
    "print(\"R2 on test data2: \" + str(test_results2.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [3.323132735646495,-10792.969087636659,6590.044462744225]\n",
      "Intercept: -136246.28670244865\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression on train data --by changing some parameters\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr1 = LinearRegression(featuresCol = 'features', labelCol='GDP Value', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model1= lr1.fit(train_data)\n",
    "print(\"Coefficients: \" + str(lr_model1.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model1.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.0,3.331813322936408e-05]\n",
      "Intercept: 12.981333348351374\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression on train data\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr2 = LinearRegression(featuresCol = 'features', labelCol='2016gwg', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model2 = lr2.fit(train_data2)\n",
    "print(\"Coefficients: \" + str(lr_model2.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model2.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+--------------------+\n",
      "|        prediction|GDP Value|            features|\n",
      "+------------------+---------+--------------------+\n",
      "|-85840.83391593977| 23802.34|[13589.05,6.56,11...|\n",
      "| -92759.6094053844| 29862.34|[24242.35,9.26,9.54]|\n",
      "|-45997.12983585165| 28783.54|[24748.29,6.75,12...|\n",
      "|-45997.12983585165| 83613.58|[24748.29,6.75,12...|\n",
      "|-43198.09818500299| 31471.88|[25029.41,9.16,16.5]|\n",
      "+------------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) = 0.415814\n",
      "Mean Absolute Error (MAE) = 999428\n",
      "Root Mean Squared Error (RMSE) = 2.44785e+06\n"
     ]
    }
   ],
   "source": [
    "#linear regression algorithm\n",
    "\n",
    "#for dataset 1\n",
    "\n",
    "lr_predictions1 = lr_model1.transform(test_data) \n",
    "lr_predictions1.select(\"prediction\",\"GDP Value\",\"features\").show(5)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "lrR2_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"GDP Value\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) = %g\" % lrR2_evaluator.evaluate(lr_predictions1))\n",
    "\n",
    "lrMAE_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"GDP Value\",metricName=\"mae\")\n",
    "print(\"Mean Absolute Error (MAE) = %g\" % lrMAE_evaluator.evaluate(lr_predictions1))\n",
    "\n",
    "lrRMSE_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"GDP Value\",metricName=\"rmse\")\n",
    "print(\"Root Mean Squared Error (RMSE) = %g\" % lrRMSE_evaluator.evaluate(lr_predictions1))\n",
    " \n",
    "#as seen below, this method for dataset 1 is not at all good!! only gives 41% R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+--------------------+\n",
      "|        prediction| 2016gwg|            features|\n",
      "+------------------+--------+--------------------+\n",
      "|13.574162892901448|     9.4|[10.1,29561.0,177...|\n",
      "|13.479606030796514|14.08125|[15.8,28556.0,149...|\n",
      "|13.608447251994464|14.08125|[18.0,27034.0,188...|\n",
      "| 13.68104746430125|    16.3|[18.9,35540.0,210...|\n",
      "|13.713532644199878|14.08125|[19.8,31347.0,219...|\n",
      "+------------------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) = 0.0148614\n",
      "Mean Absolute Error (MAE) = 1.80419\n",
      "Root Mean Squared Error (RMSE) = 2.88213\n"
     ]
    }
   ],
   "source": [
    "#linear regression algorithm\n",
    "\n",
    "#for dataset 2 \n",
    "\n",
    "lr_predictions2 = lr_model2.transform(test_data2) \n",
    "lr_predictions2.select(\"prediction\",\"2016gwg\",\"features\").show(5)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "lrR2_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"2016gwg\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) = %g\" % lrR2_evaluator.evaluate(lr_predictions2))\n",
    "\n",
    "lrMAE_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"2016gwg\",metricName=\"mae\")\n",
    "print(\"Mean Absolute Error (MAE) = %g\" % lrMAE_evaluator.evaluate(lr_predictions2))\n",
    "\n",
    "lrRMSE_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"2016gwg\",metricName=\"rmse\")\n",
    "print(\"Root Mean Squared Error (RMSE) = %g\" % lrRMSE_evaluator.evaluate(lr_predictions2))\n",
    "\n",
    "#as seen below, for dataset2 it gives a model with good rmse value but R2 is not accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.859803\n",
      "+------------------+--------+--------------------+\n",
      "|        prediction| 2016gwg|            features|\n",
      "+------------------+--------+--------------------+\n",
      "|               9.4|     9.4|[10.1,29561.0,177...|\n",
      "|14.081250000000002|14.08125|[15.8,28556.0,149...|\n",
      "|          14.08125|14.08125|[18.0,27034.0,188...|\n",
      "|              16.3|    16.3|[18.9,35540.0,210...|\n",
      "|          14.08125|14.08125|[19.8,31347.0,219...|\n",
      "|               4.5|     4.5|[21.0,32687.0,172...|\n",
      "|          14.08125|14.08125|[22.1,29665.0,189...|\n",
      "|          14.08125|14.08125|[22.5,39248.0,233...|\n",
      "|          14.08125|14.08125|[23.4,30533.0,221...|\n",
      "|14.081249999999999|    16.8|[23.5,49885.0,263...|\n",
      "+------------------+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Algorithm - applying to dataset 2 \n",
    "\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = '2016gwg',maxBins=50)\n",
    "dt_model2 = dt.fit(train_data2)\n",
    "dt_predictions2 = dt_model2.transform(test_data2)\n",
    "dt_evaluator2 = RegressionEvaluator(\n",
    "    labelCol=\"2016gwg\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator2.evaluate(dt_predictions2)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "dt_predictions2.select('prediction', '2016gwg', 'features').show(10)\n",
    "\n",
    "#Gives rmse as 0.85 which is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) = 0.912327\n",
      "+------------------+--------+--------------------+\n",
      "|        prediction| 2016gwg|            features|\n",
      "+------------------+--------+--------------------+\n",
      "|               9.4|     9.4|[10.1,29561.0,177...|\n",
      "|14.081250000000002|14.08125|[15.8,28556.0,149...|\n",
      "|          14.08125|14.08125|[18.0,27034.0,188...|\n",
      "|              16.3|    16.3|[18.9,35540.0,210...|\n",
      "|          14.08125|14.08125|[19.8,31347.0,219...|\n",
      "|               4.5|     4.5|[21.0,32687.0,172...|\n",
      "|          14.08125|14.08125|[22.1,29665.0,189...|\n",
      "|          14.08125|14.08125|[22.5,39248.0,233...|\n",
      "|          14.08125|14.08125|[23.4,30533.0,221...|\n",
      "|14.081249999999999|    16.8|[23.5,49885.0,263...|\n",
      "+------------------+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"2016gwg\",metricName=\"r2\")\n",
    "r2=r_evaluator.evaluate(dt_predictions2)\n",
    "print(\"R Squared (R2) = %g\" % r2)\n",
    "dt_predictions2.select('prediction', '2016gwg', 'features').show(10)\n",
    "\n",
    "\n",
    "#R2 value 0.91is really good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 3.37456e+06\n",
      "+----------+---------+--------------------+\n",
      "|prediction|GDP Value|            features|\n",
      "+----------+---------+--------------------+\n",
      "|      16.5| 23802.34|[13589.05,6.56,11...|\n",
      "|      16.5| 29862.34|[24242.35,9.26,9.54]|\n",
      "|      16.5| 28783.54|[24748.29,6.75,12...|\n",
      "|      16.5| 83613.58|[24748.29,6.75,12...|\n",
      "|      16.5| 31471.88|[25029.41,9.16,16.5]|\n",
      "|      16.5| 64935.93|[25029.41,12.06,1...|\n",
      "|      16.5| 32729.61|[25936.72,5.22,17...|\n",
      "|      16.5| 67574.53|[25936.72,5.22,17...|\n",
      "|      16.5|  85652.1|[26197.98,6.95,12...|\n",
      "|      16.5| 31471.88|[26666.99,6.75,19...|\n",
      "+----------+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Algorithm - applying to dataset 1 \n",
    "\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'GDP Value',maxBins=50)\n",
    "dt_model = dt.fit(train_data)\n",
    "dt_predictions = dt_model2.transform(test_data)\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"GDP Value\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "dt_predictions.select('prediction', 'GDP Value', 'features').show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) = -0.110232\n",
      "+----------+---------+--------------------+\n",
      "|prediction|GDP Value|            features|\n",
      "+----------+---------+--------------------+\n",
      "|      16.5| 23802.34|[13589.05,6.56,11...|\n",
      "|      16.5| 29862.34|[24242.35,9.26,9.54]|\n",
      "|      16.5| 28783.54|[24748.29,6.75,12...|\n",
      "|      16.5| 83613.58|[24748.29,6.75,12...|\n",
      "|      16.5| 31471.88|[25029.41,9.16,16.5]|\n",
      "|      16.5| 64935.93|[25029.41,12.06,1...|\n",
      "|      16.5| 32729.61|[25936.72,5.22,17...|\n",
      "|      16.5| 67574.53|[25936.72,5.22,17...|\n",
      "|      16.5|  85652.1|[26197.98,6.95,12...|\n",
      "|      16.5| 31471.88|[26666.99,6.75,19...|\n",
      "+----------+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"GDP Value\",metricName=\"r2\")\n",
    "r2=r_evaluator.evaluate(dt_predictions)\n",
    "print(\"R Squared (R2) = %g\" % r2)\n",
    "dt_predictions.select('prediction', 'GDP Value', 'features').show(10)\n",
    "\n",
    "\n",
    "#R2 is minus, says this does not suit dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AS SEEN, ONLY THE DATASET2 WITH PARTICULAR FEATURES GIVES AN ACCURATE MODEL 91% PREDICTION POWER.\n",
    "\n",
    "(can be applied and seen with other attributes of dataset 2, if time permits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the split value and iterating--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           2016gwg|\n",
      "+-------+------------------+\n",
      "|  count|                48|\n",
      "|   mean|13.916666666666663|\n",
      "| stddev| 2.527794079390451|\n",
      "|    min|               4.5|\n",
      "|    max|              18.1|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|           2016gwg|\n",
      "+-------+------------------+\n",
      "|  count|                16|\n",
      "|   mean|13.660937500000005|\n",
      "| stddev|2.2321858448241567|\n",
      "|    min|               7.8|\n",
      "|    max|              18.1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Iteration 2 with dataset 2  -70/30 split\n",
    "\n",
    "# Let's do a randomised 70/30 split. \n",
    "train_data2,test_data2 = vector_output2.randomSplit([0.7,0.3])\n",
    "\n",
    "# Let's see our training data.\n",
    "train_data2.describe().show()\n",
    "\n",
    "# And our testing data.\n",
    "test_data2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [4.043977049925853,-18182.42848105325,10512.164639303077]\n",
      "Intercept: -256737.21352440442\n",
      "\n",
      "RMSE: 2084955.9206300266\n",
      "R2: 0.3668494808288326\n",
      "\n",
      "Coefficients: [0.02852237395665148,1.3420948370530414e-05,1.2153456555468153e-05]\n",
      "Intercept: 12.154099010516255\n",
      "\n",
      "RMSE: 2.4512457243638575\n",
      "R2: 0.03964081777278661\n"
     ]
    }
   ],
   "source": [
    "# Importing the LR package.\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Instantiate the instance.\n",
    "lr = LinearRegression(featuresCol='features', labelCol='GDP Value')\n",
    "lr2=LinearRegression(featuresCol='features', labelCol='2016gwg')\n",
    "# Fit the training data.\n",
    "\n",
    "train_data,test_data = vector_output.randomSplit([0.7,0.3])\n",
    "\n",
    "lr_model = lr.fit(train_data)\n",
    "lr_model2 = lr2.fit(train_data2)\n",
    "# Print the coefficients.\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "\n",
    "# Print the intercept.\n",
    "print(\"Intercept: \" + str(lr_model.intercept) + \"\\n\")\n",
    "\n",
    "# Summarise the model and print out some evaluation metrics.\n",
    "training_summary = lr_model.summary\n",
    "\n",
    "# Print RMSE. \n",
    "print(\"RMSE: \" + str(training_summary.rootMeanSquaredError))\n",
    "\n",
    "# Print R2.\n",
    "print(\"R2: \" + str(training_summary.r2))\n",
    "\n",
    "#dataset 2\n",
    "\n",
    "# Print the coefficients.\n",
    "print(\"\\nCoefficients: \" + str(lr_model2.coefficients))\n",
    "\n",
    "# Print the intercept.\n",
    "print(\"Intercept: \" + str(lr_model2.intercept) + \"\\n\")\n",
    "\n",
    "\n",
    "# Summarise the model and print out some evaluation metrics.\n",
    "training_summary2 = lr_model2.summary\n",
    "\n",
    "# Print RMSE. \n",
    "print(\"RMSE: \" + str(training_summary2.rootMeanSquaredError))\n",
    "\n",
    "# Print R2.\n",
    "print(\"R2: \" + str(training_summary2.r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data: 2068764.9642582173\n",
      "R2 on test data: 0.3516309120621469\n"
     ]
    }
   ],
   "source": [
    "#Dataset 1 with 70/30 --no changes in split but output is changed\n",
    "# Evaluating the modelagainst the test data.\n",
    "test_results = lr_model.evaluate(test_data)\n",
    "\n",
    "# And print the RMSE/R2. As expected, our RMSE and R2 are slightly worse when applying the testing set.\n",
    "print(\"RMSE on test data: \" + str(test_results.rootMeanSquaredError))\n",
    "print(\"R2 on test data: \" + str(test_results.r2))\n",
    "\n",
    "#Both test and train have almost same values for R2 and rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data2: 2.093661266798269\n",
      "R2 on test data2: 0.06161542307065859\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model against the test data.\n",
    "test_results2 = lr_model2.evaluate(test_data2)\n",
    "\n",
    "# And print the RMSE/R2. As expected, our RMSE and R2 are slightly worse when applying the testing set.\n",
    "print(\"RMSE on test data2: \" + str(test_results2.rootMeanSquaredError))\n",
    "print(\"R2 on test data2: \" + str(test_results2.r2))\n",
    "\n",
    "#In test results, the R2 value increased and shifted more towards 1-- good sign!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+--------------------+\n",
      "|        prediction| 2016gwg|            features|\n",
      "+------------------+--------+--------------------+\n",
      "| 13.05515809475113|     9.4|[10.1,29561.0,177...|\n",
      "|13.057065272600136|14.08125|[14.4,27034.0,106...|\n",
      "|13.259076019271923|14.08125|[18.0,27034.0,188...|\n",
      "| 14.08561004191009|    18.1|[19.4,64406.0,422...|\n",
      "| 13.41253145985605|14.08125|[22.1,29665.0,189...|\n",
      "+------------------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) = 0.0616154\n",
      "Mean Absolute Error (MAE) = 1.21169\n",
      "Root Mean Squared Error (RMSE) = 2.09366\n"
     ]
    }
   ],
   "source": [
    "#linear regression algorithm using Regression Evaluator\n",
    "\n",
    "#for dataset 2 \n",
    "\n",
    "lr_predictions2 = lr_model2.transform(test_data2) \n",
    "lr_predictions2.select(\"prediction\",\"2016gwg\",\"features\").show(5)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "lrR2_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"2016gwg\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) = %g\" % lrR2_evaluator.evaluate(lr_predictions2))\n",
    "\n",
    "lrMAE_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"2016gwg\",metricName=\"mae\")\n",
    "print(\"Mean Absolute Error (MAE) = %g\" % lrMAE_evaluator.evaluate(lr_predictions2))\n",
    "\n",
    "lrRMSE_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"2016gwg\",metricName=\"rmse\")\n",
    "print(\"Root Mean Squared Error (RMSE) = %g\" % lrRMSE_evaluator.evaluate(lr_predictions2))\n",
    "\n",
    "# 61% accuracy with linear regression on dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.142637\n",
      "+------------------+--------+--------------------+\n",
      "|        prediction| 2016gwg|            features|\n",
      "+------------------+--------+--------------------+\n",
      "|               9.4|     9.4|[10.1,29561.0,177...|\n",
      "|14.081250000000002|14.08125|[14.4,27034.0,106...|\n",
      "|          14.08125|14.08125|[18.0,27034.0,188...|\n",
      "|              18.1|    18.1|[19.4,64406.0,422...|\n",
      "|         14.190625|14.08125|[22.1,29665.0,189...|\n",
      "|14.081250000000002|14.08125|[22.5,39248.0,233...|\n",
      "|14.396527777777784|14.08125|[28.5,66105.0,468...|\n",
      "|14.081250000000002|14.08125|[30.1,44844.0,229...|\n",
      "|14.081250000000002|14.08125|[30.1,44844.0,229...|\n",
      "|14.396527777777784|14.08125|[30.3,57882.0,298...|\n",
      "+------------------+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Algorithm - applying to dataset 2\n",
    "\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = '2016gwg',maxBins=50)\n",
    "dt_model2 = dt.fit(train_data2)\n",
    "dt_predictions2 = dt_model2.transform(test_data2)\n",
    "dt_evaluator2 = RegressionEvaluator(\n",
    "    labelCol=\"2016gwg\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator2.evaluate(dt_predictions2)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "dt_predictions2.select('prediction', '2016gwg', 'features').show(10)\n",
    "\n",
    "#low value of rmse--good sign!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) = 0.995645\n",
      "+------------------+--------+--------------------+\n",
      "|        prediction| 2016gwg|            features|\n",
      "+------------------+--------+--------------------+\n",
      "|               9.4|     9.4|[10.1,29561.0,177...|\n",
      "|14.081250000000002|14.08125|[14.4,27034.0,106...|\n",
      "|          14.08125|14.08125|[18.0,27034.0,188...|\n",
      "|              18.1|    18.1|[19.4,64406.0,422...|\n",
      "|         14.190625|14.08125|[22.1,29665.0,189...|\n",
      "|14.081250000000002|14.08125|[22.5,39248.0,233...|\n",
      "|14.396527777777784|14.08125|[28.5,66105.0,468...|\n",
      "|14.081250000000002|14.08125|[30.1,44844.0,229...|\n",
      "|14.081250000000002|14.08125|[30.1,44844.0,229...|\n",
      "|14.396527777777784|14.08125|[30.3,57882.0,298...|\n",
      "+------------------+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"2016gwg\",metricName=\"r2\")\n",
    "r2=r_evaluator.evaluate(dt_predictions2)\n",
    "print(\"R Squared (R2) = %g\" % r2)\n",
    "dt_predictions2.select('prediction', '2016gwg', 'features').show(10)\n",
    "\n",
    "#gives approximately 99% accuracy when 70/30 split is done in dataset2--- great!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
